\chapter{Problem Definition}
\label{prob-def}
\section{Introduction}
Cloud computing has been on rise over the last decade. Parts of this popularity is due to its inherent features. It lets application developers to run their applications on virtual infrastructure. Virtual infrastructure lays the foundation of on-demand infrastructure. Developers acquire and release resources as required by workload. Examples of cloud providers are Amazon AWS~\cite{aws}, Microsoft Azure~\cite{azure} and Google Cloud~\cite{gc}. Today's cloud infrastructure is widely used by many customers for different purposes such as batch processing, serving static content, storage servers and alike.

As cloud environment brings up \emph{elasticity}~\cite{Roman:2013}, it also introduces a new set of challenges and problems. Modern applications face fluctuating workloads. Typically, if a workload is \emph{predictable}, resources are allocated ahead of time before load-spike starts. However, in many other scenarios predicting even near future workload is a not so easy task. Even though running an application in cloud environments helps to overcome a long standing problem of \emph{over-provisioning}, low utilization is still one of the major problems of cloud applications. This has been confirmed by multiple studies~\cite{Delimitrou:2014}~\cite{Reiss:2012}.

The root of the problem is originated from the fact that, most developers do not have enough insight about bottom and peak workload of their application. Thus, they fail to define an effective scaling strategy. Therefore, they end up with conservative strategies which in turn leads to low utilization. Hence, we need a system that automates the process of resource allocation. Auto-Scaling has been well studied in the context of web application.~\cite{Hasan2012IntegratedAA}~\cite{Dutreilh2010}~\cite{Herbst:2013} are just a few examples. Chapter~\ref{related} explores more techniques and strategies.

\section{Objectives of Auto-Scaling Systems}
The ultimate goal of an Auto-Scaling system is to automate the process of acquiring and releasing \emph{resources} in order to minimize the \emph{cost} with minimum violation of \emph{service level objectives} (SLO). The definition of \emph{resource} depends on the context. As an example, for a stateless web applications it means virtual machines or containers that run web server software. For an Auto-Scaling system to adjust required resources, it shall consider different aspects of application and environment. Additionally, the term \emph{cost} is also defined in the context. As an example, it might mean monetary cost or just numerical value of resources. SLOs are predefined rules that shall not be violated during application runtime and are also defined in the context of application.

\section{Auto-Scaling in Data Stream Processing Systems}
\emph{Data Stream Processing Systems} are data processing systems that process \emph{unbounded} stream of data unlike their \emph{batch-oriented} counterparts. With the ever increasing adoption of IoT applications, it is critical to design stream processing systems that handles the incoming messages with high throughput and low latency. With static workloads, these problems could be solved by dominating stream processing systems like Apache Spark~\cite{spark}, Apache Storm~\cite{Storm} and Apache Flink~\cite{flink}. However, the problem of low utilization also applies for stream processing systems as well. This leads us to a new generation of stream processing systems called \emph{Elastic Data Processing Systems} that adopts elasticity concepts to stream processing system.

Prior to this thesis a number of studies have been performed on elastic stream processing system. \cite{CastroFernandez:2013},~\cite{Heinze:2014} are just a few samples. One of the dominating stream processing systems is Apache Spark which support both batch and stream processing. In order to support both workloads, Apache Spark has a unique architecture that partitions the input workload into predefined window of batches -- an architecture known as micro batching. With this common architecture as a foundation, number of interesting challenges arise that need to be considered for elastic workloads.

This thesis will focus on dynamic resource allocation in the context of Apache Spark. An extensible framework will be developed based on a prior work by \textcite{Michal:2017}. This thesis will extend the existing prototype and implement multiple Auto-Scaling techniques for Apache Spark Streaming and will evaluate these techniques using real-world workloads. The ultimate goal is to identify how the architecture of Spark Streaming influences the performance of the different Auto-Scaling techniques.

\section{Summary}
As mentioned this thesis will focus on dynamic resource allocation in the context of Apache Spark. The thesis is organized as follows. Chapter~\ref{intro-auto-scale} introduces and explains basics of Auto-Scaling techniques. Chapter~\ref{spark} introduces the architecture of Apache Spark Streaming. Chapter~\ref{design} explains structure and design considerations of this thesis. Chapter~\ref{detail} discusses implementation details and challenges faced during implementation. Chapter~\ref{eval} evaluates the implementation under different workloads. Chapter~\ref{related} includes discussion of prior and related work. Finally, chapter~\ref{conc} concludes.