\begin{abstract}
Many modern cloud-based applications face ever changing dynamic workloads. The rise of IOT with devices around the globe getting online and offline with no particular pattern, makes the situation even worse. This problem is magnified in streaming applications that are sensitive to latency. Since the workload pattern is partially unpredictable, application developers inevitably over-provision resources in order to meet customers' requirements which leads to cost inefficiencies. To resolve this issue, researchers have come up with a new class of resource managers that automatically determine workload characteristics and adopt the application to fit the workload.

In this thesis a dynamic resource manager is developed for Spark Streaming. Q-Learning is used as a foundation algorithm. To overcome the slow learning problem of Q-Learning, numerous optimizations are applied. Namely, an optimized state space initializer that is independent of workload is developed. Furthermore, Value Iteration algorithm is developed to help initialize the state table by applying minimal training period. The solution can be used by any Spark Streaming job without applying any modification to Spark.

The proposed implementation is evaluated under an extensive list of experiments based on two real world workloads. It is able to outperform the default Spark's dynamic resource manager. However, it also illustrates the fragility of the approach by changing a single configuration parameter. As a consequence, the problem of dynamic resource management still hasn't been solved. It has been moved to configuration space. Application developers have to run many manual experiments to find out the optimal configuration.
\end{abstract}